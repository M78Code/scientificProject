{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905fa0a1-f879-4976-a7f8-da6733c86885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitsandbytes: 专为量化设计的库，重点在于减少大模型（尤其是在GPU上）的内存占用\n",
    "# peft: 用于将LoRA适配器集成到大语言模型（LLMs）中\n",
    "# trl: 该库包含一个SFT（监督微调）类，用于辅助微调模型\n",
    "# accelerate和xformers: 这些库用于提高模型的推理速度，从而优化其性能\n",
    "# wandb: 该工具作为一个监控平台，用于跟踪和观察训练过程\n",
    "# datasets: 与Hugging Face一起使用，该库便于加载数据集\n",
    "\n",
    "import torch \n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    TextStreamer,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "import os, wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc711b9-c599-4d47-bfdb-765c297f4080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583cd85d-eff4-4afb-a63e-133353d8bc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221cc396-efb3-45a1-9b83-7fab3e136369",
   "metadata": {},
   "source": [
    "# 1. 加载模型和Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4605d48b-a675-4042-a3ec-db5c25883f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预训练模型\n",
    "model_name = \"/home/leon/projects/models/Meta-Llama-3-8B/\"\n",
    "# 数据集名称\n",
    "dataset_name = \"scooterman/guanaco-llama3-1k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7d4d00-8a9d-42ba-82cb-e5ef6a5b19de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a48881ac53148aeb115fbb24c028a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练模型和tokenizer\n",
    "\n",
    "# 量化配置\n",
    "# https://huggingface.co/docs/transformers/v4.43.3/en/main_classes/quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 模型将以4位量化格式加载\n",
    "    bnb_4bit_quant_type=\"nf4\", # 指定4位量化的类型为 nf4\n",
    "    bnb_4bit_compute_dtype=torch.float16, # 计算数据类型\n",
    "    bnb_4bit_use_double_quant=False, # 表示不使用双重量化\n",
    ") # QLoRA中的原理\n",
    "\n",
    "# 模型加载\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\":0} # 将模型加载到设备0（通常是第一个GPU）\n",
    ")\n",
    "\n",
    "# tokenizer 加载\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True # 在生成序列时会自动添加结束标记\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fc0bf0-f616-4205-933d-9d8f1801f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_header_id|>user<|end_header_id|>{{Me gradué hace poco de la carrera de medicina ¿Me podrías aconsejar para conseguir rápidamente un puesto de trabajo?}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>{{Esto vale tanto para médicos como para cualquier otra profesión tras finalizar los estudios aniversarios y mi consejo sería preguntar a cuántas personas haya conocido mejor. En este caso, mi primera opción sería hablar con otros profesionales médicos, echar currículos en hospitales y cualquier centro de salud. En paralelo, trabajaría por mejorar mi marca personal como médico mediante un blog o formas digitales de comunicación como los vídeos. Y, para mejorar las posibilidades de encontrar trabajo, también participaría en congresos y encuentros para conseguir más contactos. Y, además de todo lo anterior, seguiría estudiando para presentarme a las oposiciones y ejercer la medicina en el sector público de mi país.}}<|eot_id|>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据集\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a87a668-d327-45f8-8e72-454d64cfb0bd",
   "metadata": {},
   "source": [
    "# 2. wandb 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10077622-6e9c-428b-a3db-7679b0d2d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mub313leon\u001b[0m (\u001b[33mleon-2003ub313\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/leon/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 监控\n",
    "# 需要在WandB官网注册账号\n",
    "wandb.login(key=\"ded693cc7edc0388564a53cb198473dc9a10e543\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8936a6-0577-415a-8492-7d97a7811dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leon/night_task/scientificProject/src/fine_tuning/wandb/run-20240727_174700-8xhdr2ge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leon-2003ub313/test_fine_tuning/runs/8xhdr2ge' target=\"_blank\">legendary-puddle-2</a></strong> to <a href='https://wandb.ai/leon-2003ub313/test_fine_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leon-2003ub313/test_fine_tuning' target=\"_blank\">https://wandb.ai/leon-2003ub313/test_fine_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/leon-2003ub313/test_fine_tuning/runs/8xhdr2ge' target=\"_blank\">https://wandb.ai/leon-2003ub313/test_fine_tuning/runs/8xhdr2ge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"test_fine_tuning\",\n",
    "    job_type=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a666d8e9-1b8f-48f1-8719-976b88309444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算训练参数量\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params=0\n",
    "    all_param=0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "        print(f\"训练参数量: {trainable_params} || 总的参数量: {all_param} || 训练参数量占比%: {100*(trainable_params/all_param):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2b4fd-fe12-4083-8aa6-4648cc654fd2",
   "metadata": {},
   "source": [
    "# 3. LoRA与训练超参配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3163472a-eee8-4a2f-a568-259f5c0cc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r = 8,\n",
    "    lora_alpha=16, # 小技巧，把a值设置成rank值的两倍\n",
    "    # scaling = alpha / r # LoRA权重的值越大，影响就越大\n",
    "    # weight += (lora_B @ lora_A)*scaling\n",
    "    lora_dropout = 0.05,\n",
    "    bias = \"none\",\n",
    "    task_type = \"CAUSAL_LM\",\n",
    "    # [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\",\"embed_tokens\",\"lm_head\"]\n",
    "    target_modules = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "647f90c9-a876-4c02-81c8-43270c06e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# 训练超参\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"/home/leon/projects/models/autodl-tmp/\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2, # 梯度累积步数为2，即每2步更新一次梯度，有肋于在显存有限的情况下使用较大的有效批次大小。\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    save_steps=50, # 每100步保存一次模型\n",
    "    logging_steps=30,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001, # 权重衰减系数，用于L2正则化，帮助防止过拟合。\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3, # 最大梯度范数，用于梯度裁剪，防止梯度爆炸，\n",
    "    max_steps=-1, # 最大训练步数－1，表示没有限制，\n",
    "    warmup_ratio=0.3, # 预热阶段的比例，在训练开始时，学习率会逐渐升高，预热比例为0.3表示前30％的训练步骤用于预热。\n",
    "    group_by_length=True, # 按序列长度分组，以提高训练效率，\n",
    "    lr_scheduler_type=\"linear\", # 表示使用线性学习率调度。\n",
    "    report_to=\"wandb\", # tensorboard\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e9a39-5b0d-4b2a-aaad-0890e8dee484",
   "metadata": {},
   "source": [
    "# 4. 模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "164a1dd5-5f47-4e03-b943-e9cde2855724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/anaconda3/envs/llama/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/leon/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/leon/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/home/leon/anaconda3/envs/llama/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:278: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/leon/anaconda3/envs/llama/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field=\"text\",\n",
    "    args=training_arguments,\n",
    "    packing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51802e42-3148-4754-8b76-d9b2ff224334",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.82 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 开始训练\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:440\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 440\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/trainer.py:3307\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3307\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3311\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/trainer.py:3338\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3337\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3338\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3340\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/peft/peft_model.py:1430\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1429\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1441\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/peft/tuners/tuners_utils.py:179\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:1174\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1171\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:978\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    967\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    968\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    969\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         cache_position,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:732\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 732\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    735\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:215\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/peft/tuners/lora/bnb.py:458\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_layer(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# As per Tim Dettmers, for 4bit, we need to defensively clone here.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# The reason is that in some cases, an error can occur that backprop\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# does not work on a manipulated view. This issue may be solved with\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# newer PyTorch versions but this would need extensive testing to be\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# sure.\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m active_adapter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapters:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m active_adapter \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_A\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.82 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "144bdd58-1f34-40be-aedb-9546f5ec548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练参数量: 0 || 总的参数量: 525336576 || 训练参数量占比%: 0.00\n",
      "训练参数量: 0 || 总的参数量: 533725184 || 训练参数量占比%: 0.00\n",
      "训练参数量: 32768 || 总的参数量: 533757952 || 训练参数量占比%: 0.01\n",
      "训练参数量: 65536 || 总的参数量: 533790720 || 训练参数量占比%: 0.01\n",
      "训练参数量: 65536 || 总的参数量: 535887872 || 训练参数量占比%: 0.01\n",
      "训练参数量: 98304 || 总的参数量: 535920640 || 训练参数量占比%: 0.02\n",
      "训练参数量: 106496 || 总的参数量: 535928832 || 训练参数量占比%: 0.02\n",
      "训练参数量: 106496 || 总的参数量: 538025984 || 训练参数量占比%: 0.02\n",
      "训练参数量: 139264 || 总的参数量: 538058752 || 训练参数量占比%: 0.03\n",
      "训练参数量: 147456 || 总的参数量: 538066944 || 训练参数量占比%: 0.03\n",
      "训练参数量: 147456 || 总的参数量: 546455552 || 训练参数量占比%: 0.03\n",
      "训练参数量: 180224 || 总的参数量: 546488320 || 训练参数量占比%: 0.03\n",
      "训练参数量: 212992 || 总的参数量: 546521088 || 训练参数量占比%: 0.04\n",
      "训练参数量: 212992 || 总的参数量: 575881216 || 训练参数量占比%: 0.04\n",
      "训练参数量: 245760 || 总的参数量: 575913984 || 训练参数量占比%: 0.04\n",
      "训练参数量: 360448 || 总的参数量: 576028672 || 训练参数量占比%: 0.06\n",
      "训练参数量: 360448 || 总的参数量: 605388800 || 训练参数量占比%: 0.06\n",
      "训练参数量: 393216 || 总的参数量: 605421568 || 训练参数量占比%: 0.06\n",
      "训练参数量: 507904 || 总的参数量: 605536256 || 训练参数量占比%: 0.08\n",
      "训练参数量: 507904 || 总的参数量: 634896384 || 训练参数量占比%: 0.08\n",
      "训练参数量: 507904 || 总的参数量: 634900480 || 训练参数量占比%: 0.08\n",
      "训练参数量: 507904 || 总的参数量: 634904576 || 训练参数量占比%: 0.08\n",
      "训练参数量: 507904 || 总的参数量: 643293184 || 训练参数量占比%: 0.08\n",
      "训练参数量: 540672 || 总的参数量: 643325952 || 训练参数量占比%: 0.08\n",
      "训练参数量: 573440 || 总的参数量: 643358720 || 训练参数量占比%: 0.09\n",
      "训练参数量: 573440 || 总的参数量: 645455872 || 训练参数量占比%: 0.09\n",
      "训练参数量: 606208 || 总的参数量: 645488640 || 训练参数量占比%: 0.09\n",
      "训练参数量: 614400 || 总的参数量: 645496832 || 训练参数量占比%: 0.10\n",
      "训练参数量: 614400 || 总的参数量: 647593984 || 训练参数量占比%: 0.09\n",
      "训练参数量: 647168 || 总的参数量: 647626752 || 训练参数量占比%: 0.10\n",
      "训练参数量: 655360 || 总的参数量: 647634944 || 训练参数量占比%: 0.10\n",
      "训练参数量: 655360 || 总的参数量: 656023552 || 训练参数量占比%: 0.10\n",
      "训练参数量: 688128 || 总的参数量: 656056320 || 训练参数量占比%: 0.10\n",
      "训练参数量: 720896 || 总的参数量: 656089088 || 训练参数量占比%: 0.11\n",
      "训练参数量: 720896 || 总的参数量: 685449216 || 训练参数量占比%: 0.11\n",
      "训练参数量: 753664 || 总的参数量: 685481984 || 训练参数量占比%: 0.11\n",
      "训练参数量: 868352 || 总的参数量: 685596672 || 训练参数量占比%: 0.13\n",
      "训练参数量: 868352 || 总的参数量: 714956800 || 训练参数量占比%: 0.12\n",
      "训练参数量: 901120 || 总的参数量: 714989568 || 训练参数量占比%: 0.13\n",
      "训练参数量: 1015808 || 总的参数量: 715104256 || 训练参数量占比%: 0.14\n",
      "训练参数量: 1015808 || 总的参数量: 744464384 || 训练参数量占比%: 0.14\n",
      "训练参数量: 1015808 || 总的参数量: 744468480 || 训练参数量占比%: 0.14\n",
      "训练参数量: 1015808 || 总的参数量: 744472576 || 训练参数量占比%: 0.14\n",
      "训练参数量: 1015808 || 总的参数量: 752861184 || 训练参数量占比%: 0.13\n",
      "训练参数量: 1048576 || 总的参数量: 752893952 || 训练参数量占比%: 0.14\n",
      "训练参数量: 1081344 || 总的参数量: 752926720 || 训练参数量占比%: 0.14\n",
      "训练参数量: 1081344 || 总的参数量: 755023872 || 训练参数量占比%: 0.14\n",
      "训练参数量: 1114112 || 总的参数量: 755056640 || 训练参数量占比%: 0.15\n",
      "训练参数量: 1122304 || 总的参数量: 755064832 || 训练参数量占比%: 0.15\n",
      "训练参数量: 1122304 || 总的参数量: 757161984 || 训练参数量占比%: 0.15\n",
      "训练参数量: 1155072 || 总的参数量: 757194752 || 训练参数量占比%: 0.15\n",
      "训练参数量: 1163264 || 总的参数量: 757202944 || 训练参数量占比%: 0.15\n",
      "训练参数量: 1163264 || 总的参数量: 765591552 || 训练参数量占比%: 0.15\n",
      "训练参数量: 1196032 || 总的参数量: 765624320 || 训练参数量占比%: 0.16\n",
      "训练参数量: 1228800 || 总的参数量: 765657088 || 训练参数量占比%: 0.16\n",
      "训练参数量: 1228800 || 总的参数量: 795017216 || 训练参数量占比%: 0.15\n",
      "训练参数量: 1261568 || 总的参数量: 795049984 || 训练参数量占比%: 0.16\n",
      "训练参数量: 1376256 || 总的参数量: 795164672 || 训练参数量占比%: 0.17\n",
      "训练参数量: 1376256 || 总的参数量: 824524800 || 训练参数量占比%: 0.17\n",
      "训练参数量: 1409024 || 总的参数量: 824557568 || 训练参数量占比%: 0.17\n",
      "训练参数量: 1523712 || 总的参数量: 824672256 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1523712 || 总的参数量: 854032384 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1523712 || 总的参数量: 854036480 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1523712 || 总的参数量: 854040576 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1523712 || 总的参数量: 862429184 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1556480 || 总的参数量: 862461952 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1589248 || 总的参数量: 862494720 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1589248 || 总的参数量: 864591872 || 训练参数量占比%: 0.18\n",
      "训练参数量: 1622016 || 总的参数量: 864624640 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1630208 || 总的参数量: 864632832 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1630208 || 总的参数量: 866729984 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1662976 || 总的参数量: 866762752 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1671168 || 总的参数量: 866770944 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1671168 || 总的参数量: 875159552 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1703936 || 总的参数量: 875192320 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1736704 || 总的参数量: 875225088 || 训练参数量占比%: 0.20\n",
      "训练参数量: 1736704 || 总的参数量: 904585216 || 训练参数量占比%: 0.19\n",
      "训练参数量: 1769472 || 总的参数量: 904617984 || 训练参数量占比%: 0.20\n",
      "训练参数量: 1884160 || 总的参数量: 904732672 || 训练参数量占比%: 0.21\n",
      "训练参数量: 1884160 || 总的参数量: 934092800 || 训练参数量占比%: 0.20\n",
      "训练参数量: 1916928 || 总的参数量: 934125568 || 训练参数量占比%: 0.21\n",
      "训练参数量: 2031616 || 总的参数量: 934240256 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2031616 || 总的参数量: 963600384 || 训练参数量占比%: 0.21\n",
      "训练参数量: 2031616 || 总的参数量: 963604480 || 训练参数量占比%: 0.21\n",
      "训练参数量: 2031616 || 总的参数量: 963608576 || 训练参数量占比%: 0.21\n",
      "训练参数量: 2031616 || 总的参数量: 971997184 || 训练参数量占比%: 0.21\n",
      "训练参数量: 2064384 || 总的参数量: 972029952 || 训练参数量占比%: 0.21\n",
      "训练参数量: 2097152 || 总的参数量: 972062720 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2097152 || 总的参数量: 974159872 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2129920 || 总的参数量: 974192640 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2138112 || 总的参数量: 974200832 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2138112 || 总的参数量: 976297984 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2170880 || 总的参数量: 976330752 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2179072 || 总的参数量: 976338944 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2179072 || 总的参数量: 984727552 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2211840 || 总的参数量: 984760320 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2244608 || 总的参数量: 984793088 || 训练参数量占比%: 0.23\n",
      "训练参数量: 2244608 || 总的参数量: 1014153216 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2277376 || 总的参数量: 1014185984 || 训练参数量占比%: 0.22\n",
      "训练参数量: 2392064 || 总的参数量: 1014300672 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2392064 || 总的参数量: 1043660800 || 训练参数量占比%: 0.23\n",
      "训练参数量: 2424832 || 总的参数量: 1043693568 || 训练参数量占比%: 0.23\n",
      "训练参数量: 2539520 || 总的参数量: 1043808256 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2539520 || 总的参数量: 1073168384 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2539520 || 总的参数量: 1073172480 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2539520 || 总的参数量: 1073176576 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2539520 || 总的参数量: 1081565184 || 训练参数量占比%: 0.23\n",
      "训练参数量: 2572288 || 总的参数量: 1081597952 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2605056 || 总的参数量: 1081630720 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2605056 || 总的参数量: 1083727872 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2637824 || 总的参数量: 1083760640 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2646016 || 总的参数量: 1083768832 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2646016 || 总的参数量: 1085865984 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2678784 || 总的参数量: 1085898752 || 训练参数量占比%: 0.25\n",
      "训练参数量: 2686976 || 总的参数量: 1085906944 || 训练参数量占比%: 0.25\n",
      "训练参数量: 2686976 || 总的参数量: 1094295552 || 训练参数量占比%: 0.25\n",
      "训练参数量: 2719744 || 总的参数量: 1094328320 || 训练参数量占比%: 0.25\n",
      "训练参数量: 2752512 || 总的参数量: 1094361088 || 训练参数量占比%: 0.25\n",
      "训练参数量: 2752512 || 总的参数量: 1123721216 || 训练参数量占比%: 0.24\n",
      "训练参数量: 2785280 || 总的参数量: 1123753984 || 训练参数量占比%: 0.25\n",
      "训练参数量: 2899968 || 总的参数量: 1123868672 || 训练参数量占比%: 0.26\n",
      "训练参数量: 2899968 || 总的参数量: 1153228800 || 训练参数量占比%: 0.25\n",
      "训练参数量: 2932736 || 总的参数量: 1153261568 || 训练参数量占比%: 0.25\n",
      "训练参数量: 3047424 || 总的参数量: 1153376256 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3047424 || 总的参数量: 1182736384 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3047424 || 总的参数量: 1182740480 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3047424 || 总的参数量: 1182744576 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3047424 || 总的参数量: 1191133184 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3080192 || 总的参数量: 1191165952 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3112960 || 总的参数量: 1191198720 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3112960 || 总的参数量: 1193295872 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3145728 || 总的参数量: 1193328640 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3153920 || 总的参数量: 1193336832 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3153920 || 总的参数量: 1195433984 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3186688 || 总的参数量: 1195466752 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3194880 || 总的参数量: 1195474944 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3194880 || 总的参数量: 1203863552 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3227648 || 总的参数量: 1203896320 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3260416 || 总的参数量: 1203929088 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3260416 || 总的参数量: 1233289216 || 训练参数量占比%: 0.26\n",
      "训练参数量: 3293184 || 总的参数量: 1233321984 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3407872 || 总的参数量: 1233436672 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3407872 || 总的参数量: 1262796800 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3440640 || 总的参数量: 1262829568 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3555328 || 总的参数量: 1262944256 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3555328 || 总的参数量: 1292304384 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3555328 || 总的参数量: 1292308480 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3555328 || 总的参数量: 1292312576 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3555328 || 总的参数量: 1300701184 || 训练参数量占比%: 0.27\n",
      "训练参数量: 3588096 || 总的参数量: 1300733952 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3620864 || 总的参数量: 1300766720 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3620864 || 总的参数量: 1302863872 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3653632 || 总的参数量: 1302896640 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3661824 || 总的参数量: 1302904832 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3661824 || 总的参数量: 1305001984 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3694592 || 总的参数量: 1305034752 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3702784 || 总的参数量: 1305042944 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3702784 || 总的参数量: 1313431552 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3735552 || 总的参数量: 1313464320 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3768320 || 总的参数量: 1313497088 || 训练参数量占比%: 0.29\n",
      "训练参数量: 3768320 || 总的参数量: 1342857216 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3801088 || 总的参数量: 1342889984 || 训练参数量占比%: 0.28\n",
      "训练参数量: 3915776 || 总的参数量: 1343004672 || 训练参数量占比%: 0.29\n",
      "训练参数量: 3915776 || 总的参数量: 1372364800 || 训练参数量占比%: 0.29\n",
      "训练参数量: 3948544 || 总的参数量: 1372397568 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4063232 || 总的参数量: 1372512256 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4063232 || 总的参数量: 1401872384 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4063232 || 总的参数量: 1401876480 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4063232 || 总的参数量: 1401880576 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4063232 || 总的参数量: 1410269184 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4096000 || 总的参数量: 1410301952 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4128768 || 总的参数量: 1410334720 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4128768 || 总的参数量: 1412431872 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4161536 || 总的参数量: 1412464640 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4169728 || 总的参数量: 1412472832 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4169728 || 总的参数量: 1414569984 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4202496 || 总的参数量: 1414602752 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4210688 || 总的参数量: 1414610944 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4210688 || 总的参数量: 1422999552 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4243456 || 总的参数量: 1423032320 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4276224 || 总的参数量: 1423065088 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4276224 || 总的参数量: 1452425216 || 训练参数量占比%: 0.29\n",
      "训练参数量: 4308992 || 总的参数量: 1452457984 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4423680 || 总的参数量: 1452572672 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4423680 || 总的参数量: 1481932800 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4456448 || 总的参数量: 1481965568 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4571136 || 总的参数量: 1482080256 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4571136 || 总的参数量: 1511440384 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4571136 || 总的参数量: 1511444480 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4571136 || 总的参数量: 1511448576 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4571136 || 总的参数量: 1519837184 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4603904 || 总的参数量: 1519869952 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4636672 || 总的参数量: 1519902720 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4636672 || 总的参数量: 1521999872 || 训练参数量占比%: 0.30\n",
      "训练参数量: 4669440 || 总的参数量: 1522032640 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4677632 || 总的参数量: 1522040832 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4677632 || 总的参数量: 1524137984 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4710400 || 总的参数量: 1524170752 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4718592 || 总的参数量: 1524178944 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4718592 || 总的参数量: 1532567552 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4751360 || 总的参数量: 1532600320 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4784128 || 总的参数量: 1532633088 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4784128 || 总的参数量: 1561993216 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4816896 || 总的参数量: 1562025984 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4931584 || 总的参数量: 1562140672 || 训练参数量占比%: 0.32\n",
      "训练参数量: 4931584 || 总的参数量: 1591500800 || 训练参数量占比%: 0.31\n",
      "训练参数量: 4964352 || 总的参数量: 1591533568 || 训练参数量占比%: 0.31\n",
      "训练参数量: 5079040 || 总的参数量: 1591648256 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5079040 || 总的参数量: 1621008384 || 训练参数量占比%: 0.31\n",
      "训练参数量: 5079040 || 总的参数量: 1621012480 || 训练参数量占比%: 0.31\n",
      "训练参数量: 5079040 || 总的参数量: 1621016576 || 训练参数量占比%: 0.31\n",
      "训练参数量: 5079040 || 总的参数量: 1629405184 || 训练参数量占比%: 0.31\n",
      "训练参数量: 5111808 || 总的参数量: 1629437952 || 训练参数量占比%: 0.31\n",
      "训练参数量: 5144576 || 总的参数量: 1629470720 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5144576 || 总的参数量: 1631567872 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5177344 || 总的参数量: 1631600640 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5185536 || 总的参数量: 1631608832 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5185536 || 总的参数量: 1633705984 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5218304 || 总的参数量: 1633738752 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5226496 || 总的参数量: 1633746944 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5226496 || 总的参数量: 1642135552 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5259264 || 总的参数量: 1642168320 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5292032 || 总的参数量: 1642201088 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5292032 || 总的参数量: 1671561216 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5324800 || 总的参数量: 1671593984 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5439488 || 总的参数量: 1671708672 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5439488 || 总的参数量: 1701068800 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5472256 || 总的参数量: 1701101568 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5586944 || 总的参数量: 1701216256 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5586944 || 总的参数量: 1730576384 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5586944 || 总的参数量: 1730580480 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5586944 || 总的参数量: 1730584576 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5586944 || 总的参数量: 1738973184 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5619712 || 总的参数量: 1739005952 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5652480 || 总的参数量: 1739038720 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5652480 || 总的参数量: 1741135872 || 训练参数量占比%: 0.32\n",
      "训练参数量: 5685248 || 总的参数量: 1741168640 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5693440 || 总的参数量: 1741176832 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5693440 || 总的参数量: 1743273984 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5726208 || 总的参数量: 1743306752 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5734400 || 总的参数量: 1743314944 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5734400 || 总的参数量: 1751703552 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5767168 || 总的参数量: 1751736320 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5799936 || 总的参数量: 1751769088 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5799936 || 总的参数量: 1781129216 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5832704 || 总的参数量: 1781161984 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5947392 || 总的参数量: 1781276672 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5947392 || 总的参数量: 1810636800 || 训练参数量占比%: 0.33\n",
      "训练参数量: 5980160 || 总的参数量: 1810669568 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6094848 || 总的参数量: 1810784256 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6094848 || 总的参数量: 1840144384 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6094848 || 总的参数量: 1840148480 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6094848 || 总的参数量: 1840152576 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6094848 || 总的参数量: 1848541184 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6127616 || 总的参数量: 1848573952 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6160384 || 总的参数量: 1848606720 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6160384 || 总的参数量: 1850703872 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6193152 || 总的参数量: 1850736640 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6201344 || 总的参数量: 1850744832 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6201344 || 总的参数量: 1852841984 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6234112 || 总的参数量: 1852874752 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6242304 || 总的参数量: 1852882944 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6242304 || 总的参数量: 1861271552 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6275072 || 总的参数量: 1861304320 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6307840 || 总的参数量: 1861337088 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6307840 || 总的参数量: 1890697216 || 训练参数量占比%: 0.33\n",
      "训练参数量: 6340608 || 总的参数量: 1890729984 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6455296 || 总的参数量: 1890844672 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6455296 || 总的参数量: 1920204800 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6488064 || 总的参数量: 1920237568 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6602752 || 总的参数量: 1920352256 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6602752 || 总的参数量: 1949712384 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6602752 || 总的参数量: 1949716480 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6602752 || 总的参数量: 1949720576 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6602752 || 总的参数量: 1958109184 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6635520 || 总的参数量: 1958141952 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6668288 || 总的参数量: 1958174720 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6668288 || 总的参数量: 1960271872 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6701056 || 总的参数量: 1960304640 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6709248 || 总的参数量: 1960312832 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6709248 || 总的参数量: 1962409984 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6742016 || 总的参数量: 1962442752 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6750208 || 总的参数量: 1962450944 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6750208 || 总的参数量: 1970839552 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6782976 || 总的参数量: 1970872320 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6815744 || 总的参数量: 1970905088 || 训练参数量占比%: 0.35\n",
      "训练参数量: 6815744 || 总的参数量: 2000265216 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6848512 || 总的参数量: 2000297984 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6963200 || 总的参数量: 2000412672 || 训练参数量占比%: 0.35\n",
      "训练参数量: 6963200 || 总的参数量: 2029772800 || 训练参数量占比%: 0.34\n",
      "训练参数量: 6995968 || 总的参数量: 2029805568 || 训练参数量占比%: 0.34\n",
      "训练参数量: 7110656 || 总的参数量: 2029920256 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7110656 || 总的参数量: 2059280384 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7110656 || 总的参数量: 2059284480 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7110656 || 总的参数量: 2059288576 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7110656 || 总的参数量: 2067677184 || 训练参数量占比%: 0.34\n",
      "训练参数量: 7143424 || 总的参数量: 2067709952 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7176192 || 总的参数量: 2067742720 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7176192 || 总的参数量: 2069839872 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7208960 || 总的参数量: 2069872640 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7217152 || 总的参数量: 2069880832 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7217152 || 总的参数量: 2071977984 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7249920 || 总的参数量: 2072010752 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7258112 || 总的参数量: 2072018944 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7258112 || 总的参数量: 2080407552 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7290880 || 总的参数量: 2080440320 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7323648 || 总的参数量: 2080473088 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7323648 || 总的参数量: 2109833216 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7356416 || 总的参数量: 2109865984 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7471104 || 总的参数量: 2109980672 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7471104 || 总的参数量: 2139340800 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7503872 || 总的参数量: 2139373568 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7618560 || 总的参数量: 2139488256 || 训练参数量占比%: 0.36\n",
      "训练参数量: 7618560 || 总的参数量: 2168848384 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7618560 || 总的参数量: 2168852480 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7618560 || 总的参数量: 2168856576 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7618560 || 总的参数量: 2177245184 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7651328 || 总的参数量: 2177277952 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7684096 || 总的参数量: 2177310720 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7684096 || 总的参数量: 2179407872 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7716864 || 总的参数量: 2179440640 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7725056 || 总的参数量: 2179448832 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7725056 || 总的参数量: 2181545984 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7757824 || 总的参数量: 2181578752 || 训练参数量占比%: 0.36\n",
      "训练参数量: 7766016 || 总的参数量: 2181586944 || 训练参数量占比%: 0.36\n",
      "训练参数量: 7766016 || 总的参数量: 2189975552 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7798784 || 总的参数量: 2190008320 || 训练参数量占比%: 0.36\n",
      "训练参数量: 7831552 || 总的参数量: 2190041088 || 训练参数量占比%: 0.36\n",
      "训练参数量: 7831552 || 总的参数量: 2219401216 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7864320 || 总的参数量: 2219433984 || 训练参数量占比%: 0.35\n",
      "训练参数量: 7979008 || 总的参数量: 2219548672 || 训练参数量占比%: 0.36\n",
      "训练参数量: 7979008 || 总的参数量: 2248908800 || 训练参数量占比%: 0.35\n",
      "训练参数量: 8011776 || 总的参数量: 2248941568 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8126464 || 总的参数量: 2249056256 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8126464 || 总的参数量: 2278416384 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8126464 || 总的参数量: 2278420480 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8126464 || 总的参数量: 2278424576 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8126464 || 总的参数量: 2286813184 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8159232 || 总的参数量: 2286845952 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8192000 || 总的参数量: 2286878720 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8192000 || 总的参数量: 2288975872 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8224768 || 总的参数量: 2289008640 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8232960 || 总的参数量: 2289016832 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8232960 || 总的参数量: 2291113984 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8265728 || 总的参数量: 2291146752 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8273920 || 总的参数量: 2291154944 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8273920 || 总的参数量: 2299543552 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8306688 || 总的参数量: 2299576320 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8339456 || 总的参数量: 2299609088 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8339456 || 总的参数量: 2328969216 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8372224 || 总的参数量: 2329001984 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8486912 || 总的参数量: 2329116672 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8486912 || 总的参数量: 2358476800 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8519680 || 总的参数量: 2358509568 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8634368 || 总的参数量: 2358624256 || 训练参数量占比%: 0.37\n",
      "训练参数量: 8634368 || 总的参数量: 2387984384 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8634368 || 总的参数量: 2387988480 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8634368 || 总的参数量: 2387992576 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8634368 || 总的参数量: 2396381184 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8667136 || 总的参数量: 2396413952 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8699904 || 总的参数量: 2396446720 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8699904 || 总的参数量: 2398543872 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8732672 || 总的参数量: 2398576640 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8740864 || 总的参数量: 2398584832 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8740864 || 总的参数量: 2400681984 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8773632 || 总的参数量: 2400714752 || 训练参数量占比%: 0.37\n",
      "训练参数量: 8781824 || 总的参数量: 2400722944 || 训练参数量占比%: 0.37\n",
      "训练参数量: 8781824 || 总的参数量: 2409111552 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8814592 || 总的参数量: 2409144320 || 训练参数量占比%: 0.37\n",
      "训练参数量: 8847360 || 总的参数量: 2409177088 || 训练参数量占比%: 0.37\n",
      "训练参数量: 8847360 || 总的参数量: 2438537216 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8880128 || 总的参数量: 2438569984 || 训练参数量占比%: 0.36\n",
      "训练参数量: 8994816 || 总的参数量: 2438684672 || 训练参数量占比%: 0.37\n",
      "训练参数量: 8994816 || 总的参数量: 2468044800 || 训练参数量占比%: 0.36\n",
      "训练参数量: 9027584 || 总的参数量: 2468077568 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9142272 || 总的参数量: 2468192256 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9142272 || 总的参数量: 2497552384 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9142272 || 总的参数量: 2497556480 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9142272 || 总的参数量: 2497560576 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9142272 || 总的参数量: 2505949184 || 训练参数量占比%: 0.36\n",
      "训练参数量: 9175040 || 总的参数量: 2505981952 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9207808 || 总的参数量: 2506014720 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9207808 || 总的参数量: 2508111872 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9240576 || 总的参数量: 2508144640 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9248768 || 总的参数量: 2508152832 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9248768 || 总的参数量: 2510249984 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9281536 || 总的参数量: 2510282752 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9289728 || 总的参数量: 2510290944 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9289728 || 总的参数量: 2518679552 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9322496 || 总的参数量: 2518712320 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9355264 || 总的参数量: 2518745088 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9355264 || 总的参数量: 2548105216 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9388032 || 总的参数量: 2548137984 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9502720 || 总的参数量: 2548252672 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9502720 || 总的参数量: 2577612800 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9535488 || 总的参数量: 2577645568 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9650176 || 总的参数量: 2577760256 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9650176 || 总的参数量: 2607120384 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9650176 || 总的参数量: 2607124480 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9650176 || 总的参数量: 2607128576 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9650176 || 总的参数量: 2615517184 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9682944 || 总的参数量: 2615549952 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9715712 || 总的参数量: 2615582720 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9715712 || 总的参数量: 2617679872 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9748480 || 总的参数量: 2617712640 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9756672 || 总的参数量: 2617720832 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9756672 || 总的参数量: 2619817984 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9789440 || 总的参数量: 2619850752 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9797632 || 总的参数量: 2619858944 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9797632 || 总的参数量: 2628247552 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9830400 || 总的参数量: 2628280320 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9863168 || 总的参数量: 2628313088 || 训练参数量占比%: 0.38\n",
      "训练参数量: 9863168 || 总的参数量: 2657673216 || 训练参数量占比%: 0.37\n",
      "训练参数量: 9895936 || 总的参数量: 2657705984 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10010624 || 总的参数量: 2657820672 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10010624 || 总的参数量: 2687180800 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10043392 || 总的参数量: 2687213568 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10158080 || 总的参数量: 2687328256 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10158080 || 总的参数量: 2716688384 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10158080 || 总的参数量: 2716692480 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10158080 || 总的参数量: 2716696576 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10158080 || 总的参数量: 2725085184 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10190848 || 总的参数量: 2725117952 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10223616 || 总的参数量: 2725150720 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10223616 || 总的参数量: 2727247872 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10256384 || 总的参数量: 2727280640 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10264576 || 总的参数量: 2727288832 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10264576 || 总的参数量: 2729385984 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10297344 || 总的参数量: 2729418752 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10305536 || 总的参数量: 2729426944 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10305536 || 总的参数量: 2737815552 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10338304 || 总的参数量: 2737848320 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10371072 || 总的参数量: 2737881088 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10371072 || 总的参数量: 2767241216 || 训练参数量占比%: 0.37\n",
      "训练参数量: 10403840 || 总的参数量: 2767273984 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10518528 || 总的参数量: 2767388672 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10518528 || 总的参数量: 2796748800 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10551296 || 总的参数量: 2796781568 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10665984 || 总的参数量: 2796896256 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10665984 || 总的参数量: 2826256384 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10665984 || 总的参数量: 2826260480 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10665984 || 总的参数量: 2826264576 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10665984 || 总的参数量: 2834653184 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10698752 || 总的参数量: 2834685952 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10731520 || 总的参数量: 2834718720 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10731520 || 总的参数量: 2836815872 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10764288 || 总的参数量: 2836848640 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10772480 || 总的参数量: 2836856832 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10772480 || 总的参数量: 2838953984 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10805248 || 总的参数量: 2838986752 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10813440 || 总的参数量: 2838994944 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10813440 || 总的参数量: 2847383552 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10846208 || 总的参数量: 2847416320 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10878976 || 总的参数量: 2847449088 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10878976 || 总的参数量: 2876809216 || 训练参数量占比%: 0.38\n",
      "训练参数量: 10911744 || 总的参数量: 2876841984 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11026432 || 总的参数量: 2876956672 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11026432 || 总的参数量: 2906316800 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11059200 || 总的参数量: 2906349568 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11173888 || 总的参数量: 2906464256 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11173888 || 总的参数量: 2935824384 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11173888 || 总的参数量: 2935828480 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11173888 || 总的参数量: 2935832576 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11173888 || 总的参数量: 2944221184 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11206656 || 总的参数量: 2944253952 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11239424 || 总的参数量: 2944286720 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11239424 || 总的参数量: 2946383872 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11272192 || 总的参数量: 2946416640 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11280384 || 总的参数量: 2946424832 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11280384 || 总的参数量: 2948521984 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11313152 || 总的参数量: 2948554752 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11321344 || 总的参数量: 2948562944 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11321344 || 总的参数量: 2956951552 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11354112 || 总的参数量: 2956984320 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11386880 || 总的参数量: 2957017088 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11386880 || 总的参数量: 2986377216 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11419648 || 总的参数量: 2986409984 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11534336 || 总的参数量: 2986524672 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11534336 || 总的参数量: 3015884800 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11567104 || 总的参数量: 3015917568 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11681792 || 总的参数量: 3016032256 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11681792 || 总的参数量: 3045392384 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11681792 || 总的参数量: 3045396480 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11681792 || 总的参数量: 3045400576 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11681792 || 总的参数量: 3053789184 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11714560 || 总的参数量: 3053821952 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11747328 || 总的参数量: 3053854720 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11747328 || 总的参数量: 3055951872 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11780096 || 总的参数量: 3055984640 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11788288 || 总的参数量: 3055992832 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11788288 || 总的参数量: 3058089984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11821056 || 总的参数量: 3058122752 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11829248 || 总的参数量: 3058130944 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11829248 || 总的参数量: 3066519552 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11862016 || 总的参数量: 3066552320 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11894784 || 总的参数量: 3066585088 || 训练参数量占比%: 0.39\n",
      "训练参数量: 11894784 || 总的参数量: 3095945216 || 训练参数量占比%: 0.38\n",
      "训练参数量: 11927552 || 总的参数量: 3095977984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12042240 || 总的参数量: 3096092672 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12042240 || 总的参数量: 3125452800 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12075008 || 总的参数量: 3125485568 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12189696 || 总的参数量: 3125600256 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12189696 || 总的参数量: 3154960384 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12189696 || 总的参数量: 3154964480 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12189696 || 总的参数量: 3154968576 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12189696 || 总的参数量: 3163357184 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12222464 || 总的参数量: 3163389952 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12255232 || 总的参数量: 3163422720 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12255232 || 总的参数量: 3165519872 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12288000 || 总的参数量: 3165552640 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12296192 || 总的参数量: 3165560832 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12296192 || 总的参数量: 3167657984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12328960 || 总的参数量: 3167690752 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12337152 || 总的参数量: 3167698944 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12337152 || 总的参数量: 3176087552 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12369920 || 总的参数量: 3176120320 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12402688 || 总的参数量: 3176153088 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12402688 || 总的参数量: 3205513216 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12435456 || 总的参数量: 3205545984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12550144 || 总的参数量: 3205660672 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12550144 || 总的参数量: 3235020800 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12582912 || 总的参数量: 3235053568 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12697600 || 总的参数量: 3235168256 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12697600 || 总的参数量: 3264528384 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12697600 || 总的参数量: 3264532480 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12697600 || 总的参数量: 3264536576 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12697600 || 总的参数量: 3272925184 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12730368 || 总的参数量: 3272957952 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12763136 || 总的参数量: 3272990720 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12763136 || 总的参数量: 3275087872 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12795904 || 总的参数量: 3275120640 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12804096 || 总的参数量: 3275128832 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12804096 || 总的参数量: 3277225984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12836864 || 总的参数量: 3277258752 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12845056 || 总的参数量: 3277266944 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12845056 || 总的参数量: 3285655552 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12877824 || 总的参数量: 3285688320 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12910592 || 总的参数量: 3285721088 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12910592 || 总的参数量: 3315081216 || 训练参数量占比%: 0.39\n",
      "训练参数量: 12943360 || 总的参数量: 3315113984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13058048 || 总的参数量: 3315228672 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13058048 || 总的参数量: 3344588800 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13090816 || 总的参数量: 3344621568 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13205504 || 总的参数量: 3344736256 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13205504 || 总的参数量: 3374096384 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13205504 || 总的参数量: 3374100480 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13205504 || 总的参数量: 3374104576 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13205504 || 总的参数量: 3382493184 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13238272 || 总的参数量: 3382525952 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13271040 || 总的参数量: 3382558720 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13271040 || 总的参数量: 3384655872 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13303808 || 总的参数量: 3384688640 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13312000 || 总的参数量: 3384696832 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13312000 || 总的参数量: 3386793984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13344768 || 总的参数量: 3386826752 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13352960 || 总的参数量: 3386834944 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13352960 || 总的参数量: 3395223552 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13385728 || 总的参数量: 3395256320 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13418496 || 总的参数量: 3395289088 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13418496 || 总的参数量: 3424649216 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13451264 || 总的参数量: 3424681984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13565952 || 总的参数量: 3424796672 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13565952 || 总的参数量: 3454156800 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13598720 || 总的参数量: 3454189568 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13713408 || 总的参数量: 3454304256 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13713408 || 总的参数量: 3483664384 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13713408 || 总的参数量: 3483668480 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13713408 || 总的参数量: 3483672576 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13713408 || 总的参数量: 3492061184 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13746176 || 总的参数量: 3492093952 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13778944 || 总的参数量: 3492126720 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13778944 || 总的参数量: 3494223872 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13811712 || 总的参数量: 3494256640 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13819904 || 总的参数量: 3494264832 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13819904 || 总的参数量: 3496361984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13852672 || 总的参数量: 3496394752 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13860864 || 总的参数量: 3496402944 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13860864 || 总的参数量: 3504791552 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13893632 || 总的参数量: 3504824320 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13926400 || 总的参数量: 3504857088 || 训练参数量占比%: 0.40\n",
      "训练参数量: 13926400 || 总的参数量: 3534217216 || 训练参数量占比%: 0.39\n",
      "训练参数量: 13959168 || 总的参数量: 3534249984 || 训练参数量占比%: 0.39\n",
      "训练参数量: 14073856 || 总的参数量: 3534364672 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14073856 || 总的参数量: 3563724800 || 训练参数量占比%: 0.39\n",
      "训练参数量: 14106624 || 总的参数量: 3563757568 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14221312 || 总的参数量: 3563872256 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14221312 || 总的参数量: 3593232384 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14221312 || 总的参数量: 3593236480 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14221312 || 总的参数量: 3593240576 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14221312 || 总的参数量: 3601629184 || 训练参数量占比%: 0.39\n",
      "训练参数量: 14254080 || 总的参数量: 3601661952 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14286848 || 总的参数量: 3601694720 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14286848 || 总的参数量: 3603791872 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14319616 || 总的参数量: 3603824640 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14327808 || 总的参数量: 3603832832 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14327808 || 总的参数量: 3605929984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14360576 || 总的参数量: 3605962752 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14368768 || 总的参数量: 3605970944 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14368768 || 总的参数量: 3614359552 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14401536 || 总的参数量: 3614392320 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14434304 || 总的参数量: 3614425088 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14434304 || 总的参数量: 3643785216 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14467072 || 总的参数量: 3643817984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14581760 || 总的参数量: 3643932672 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14581760 || 总的参数量: 3673292800 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14614528 || 总的参数量: 3673325568 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14729216 || 总的参数量: 3673440256 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14729216 || 总的参数量: 3702800384 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14729216 || 总的参数量: 3702804480 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14729216 || 总的参数量: 3702808576 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14729216 || 总的参数量: 3711197184 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14761984 || 总的参数量: 3711229952 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14794752 || 总的参数量: 3711262720 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14794752 || 总的参数量: 3713359872 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14827520 || 总的参数量: 3713392640 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14835712 || 总的参数量: 3713400832 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14835712 || 总的参数量: 3715497984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14868480 || 总的参数量: 3715530752 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14876672 || 总的参数量: 3715538944 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14876672 || 总的参数量: 3723927552 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14909440 || 总的参数量: 3723960320 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14942208 || 总的参数量: 3723993088 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14942208 || 总的参数量: 3753353216 || 训练参数量占比%: 0.40\n",
      "训练参数量: 14974976 || 总的参数量: 3753385984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15089664 || 总的参数量: 3753500672 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15089664 || 总的参数量: 3782860800 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15122432 || 总的参数量: 3782893568 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15237120 || 总的参数量: 3783008256 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15237120 || 总的参数量: 3812368384 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15237120 || 总的参数量: 3812372480 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15237120 || 总的参数量: 3812376576 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15237120 || 总的参数量: 3820765184 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15269888 || 总的参数量: 3820797952 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15302656 || 总的参数量: 3820830720 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15302656 || 总的参数量: 3822927872 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15335424 || 总的参数量: 3822960640 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15343616 || 总的参数量: 3822968832 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15343616 || 总的参数量: 3825065984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15376384 || 总的参数量: 3825098752 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15384576 || 总的参数量: 3825106944 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15384576 || 总的参数量: 3833495552 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15417344 || 总的参数量: 3833528320 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15450112 || 总的参数量: 3833561088 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15450112 || 总的参数量: 3862921216 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15482880 || 总的参数量: 3862953984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15597568 || 总的参数量: 3863068672 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15597568 || 总的参数量: 3892428800 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15630336 || 总的参数量: 3892461568 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15745024 || 总的参数量: 3892576256 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15745024 || 总的参数量: 3921936384 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15745024 || 总的参数量: 3921940480 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15745024 || 总的参数量: 3921944576 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15745024 || 总的参数量: 3930333184 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15777792 || 总的参数量: 3930365952 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15810560 || 总的参数量: 3930398720 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15810560 || 总的参数量: 3932495872 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15843328 || 总的参数量: 3932528640 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15851520 || 总的参数量: 3932536832 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15851520 || 总的参数量: 3934633984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15884288 || 总的参数量: 3934666752 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15892480 || 总的参数量: 3934674944 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15892480 || 总的参数量: 3943063552 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15925248 || 总的参数量: 3943096320 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15958016 || 总的参数量: 3943129088 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15958016 || 总的参数量: 3972489216 || 训练参数量占比%: 0.40\n",
      "训练参数量: 15990784 || 总的参数量: 3972521984 || 训练参数量占比%: 0.40\n",
      "训练参数量: 16105472 || 总的参数量: 3972636672 || 训练参数量占比%: 0.41\n",
      "训练参数量: 16105472 || 总的参数量: 4001996800 || 训练参数量占比%: 0.40\n",
      "训练参数量: 16138240 || 总的参数量: 4002029568 || 训练参数量占比%: 0.40\n",
      "训练参数量: 16252928 || 总的参数量: 4002144256 || 训练参数量占比%: 0.41\n",
      "训练参数量: 16252928 || 总的参数量: 4031504384 || 训练参数量占比%: 0.40\n",
      "训练参数量: 16252928 || 总的参数量: 4031508480 || 训练参数量占比%: 0.40\n",
      "训练参数量: 16252928 || 总的参数量: 4031512576 || 训练参数量占比%: 0.40\n",
      "训练参数量: 16252928 || 总的参数量: 4031516672 || 训练参数量占比%: 0.40\n",
      "训练参数量: 16252928 || 总的参数量: 4556853248 || 训练参数量占比%: 0.36\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model,peft_config)\n",
    "\n",
    "# 计算可训练数量\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f8379-3e19-48d4-9559-47285c4f1c2f",
   "metadata": {},
   "source": [
    "# 5. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e218befc-4110-45ad-9d55-4d58a7f7a326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/anaconda3/envs/llama/lib/python3.8/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/leon/projects/models/Meta-Llama-3-8B/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-puddle-2</strong> at: <a href='https://wandb.ai/leon-2003ub313/test_fine_tuning/runs/8xhdr2ge' target=\"_blank\">https://wandb.ai/leon-2003ub313/test_fine_tuning/runs/8xhdr2ge</a><br/> View project at: <a href='https://wandb.ai/leon-2003ub313/test_fine_tuning' target=\"_blank\">https://wandb.ai/leon-2003ub313/test_fine_tuning</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240727_174700-8xhdr2ge/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存微调模型\n",
    "\n",
    "trainer.model.save_pretrained(\"/home/leon/projects/models/autodl-tmp/\")\n",
    "wandb.finish()\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478b265-dd5d-42ae-a15f-4d8718480163",
   "metadata": {},
   "source": [
    "# 6. 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97948647-8724-41cf-8c01-a60f2fffe4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base模型测试\n",
    "\n",
    "def stream(user_input):\n",
    "    device = \"cuda:0\"\n",
    "    system_prompt = \"Below is an instruction that describes a task. Write a response that appropriately comple\"\n",
    "    B_INST, E_INST = \"### Instruction:\\n\", \"### Response:\\n\"\n",
    "    prompt = f\"{system_prompt}{B_INST}{user_input.strip()}\\n\\n{E_INST}\"\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "    _ = model.generate(**inputs, streamer=streamer, max_new_tokens=128) # 这个model是原始模型，不是微调后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d1ab4f1-e548-4d59-918f-c3fc550c2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "安倍晋三,日本首相。\n",
      "\n",
      "### Explanation:\n",
      "The sentence “安倍晋三,日本首相。” is a simple sentence. It is a statement that tells who the person is. The sentence contains one independent clause, which is the main idea of the sentence. The subject is 安倍晋三, and the predicate is 日本首相. The subject and the predicate are separated by a comma.\n"
     ]
    }
   ],
   "source": [
    "stream(\"安倍是谁\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786ba3a-9304-4d78-9cc2-ab389fc62754",
   "metadata": {},
   "source": [
    "# 7. 模型合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a0f3439-292c-4271-b1c6-c2ac19e50118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32280980dad54e0eb7be7b05057c1ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1002.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 合并base model 与 lora model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# https://huggingface.co/docs/trl/main/en/use_model#use-adapters-peft\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/modeling_utils.py:3838\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3829\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3831\u001b[0m     (\n\u001b[1;32m   3832\u001b[0m         model,\n\u001b[1;32m   3833\u001b[0m         missing_keys,\n\u001b[1;32m   3834\u001b[0m         unexpected_keys,\n\u001b[1;32m   3835\u001b[0m         mismatched_keys,\n\u001b[1;32m   3836\u001b[0m         offload_index,\n\u001b[1;32m   3837\u001b[0m         error_msgs,\n\u001b[0;32m-> 3838\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3845\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3846\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3849\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/modeling_utils.py:4298\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4294\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4295\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4296\u001b[0m                 )\n\u001b[1;32m   4297\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4298\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4299\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4303\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4305\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4306\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4313\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4315\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/transformers/modeling_utils.py:895\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    884\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    893\u001b[0m ):\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    897\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/accelerate/utils/modeling.py:404\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    402\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 404\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "# 合并base model 与 lora model\n",
    "# https://huggingface.co/docs/trl/main/en/use_model#use-adapters-peft\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, low_cpu_mem_usage=True,\n",
    "    return_dict=True,torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "754da922-7f4e-40aa-b795-42ce3c62c842",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mbase_model\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/leon/projects/models/autodl-tmp/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "new_model = PeftModel.from_pretrained(base_model, \"/home/leon/projects/models/autodl-tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c9e7b14-dd1d-4909-ad5c-ab8ab4174621",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 模型合并\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_model \u001b[38;5;241m=\u001b[39m \u001b[43mnew_model\u001b[49m\u001b[38;5;241m.\u001b[39mmerge_and_unload()\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      4\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 模型合并\n",
    "merged_model = new_model.merge_and_unload()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "def stream(user_input):\n",
    "    device = \"cuda:0\"\n",
    "    system_prompt = \"Below is an instruction that describes a task. Write a response that appropriately comple\"\n",
    "    B_INST, E_INST = \"### Instruction:\\n\", \"### Response:\\n\"\n",
    "    prompt = f\"{system_prompt}{B_INST}{user_input.strip()}\\n\\n{E_INST}\"\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "    _ = merged_model.generate(**inputs, streamer=streamer, max_new_tokens=128,num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa844b51-143d-4779-81a0-303ac7a96e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
