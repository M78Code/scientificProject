{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb579325-5fe3-487a-8332-ed66289a674c",
   "metadata": {},
   "source": [
    "# Lab for Why finetuning: compare finetuned vs. non=finetuned open-source models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd8bef-4c28-42de-a25c-b959c79fb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --force-reinstall --ignore-installed lamini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7435538f-e096-4565-b8e0-3e94f1f14ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama import BasicModelRunner\n",
    "import os\n",
    "\n",
    "# Hugging Face API key\n",
    "api_key = \"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\"\n",
    "# set environment\n",
    "os.environ[\"HUGGINGFACE_HUB_API_TOKEN\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efff5cc6-0043-43be-a662-6fdf5d67de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6e28180-a2b4-4e72-9e02-75a3353611bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Missing API Key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/rest_requests.py:151\u001b[0m, in \u001b[0;36mmake_web_request\u001b[0;34m(key, url, http_method, json)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBearer \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m,\n\u001b[1;32m    152\u001b[0m     }\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m non_finetuned_output \u001b[38;5;241m=\u001b[39m \u001b[43mnon_finetuned\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me how to train my dog to sit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/runners/base_runner.py:42\u001b[0m, in \u001b[0;36mBaseRunner.__call__\u001b[0;34m(self, prompt, system_prompt, output_type, max_tokens, max_new_tokens, callback, metadata)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     34\u001b[0m     prompt: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     metadata: Optional[List] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m ):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/runners/base_runner.py:64\u001b[0m, in \u001b[0;36mBaseRunner.call\u001b[0;34m(self, prompt, system_prompt, output_type, max_tokens, max_new_tokens, callback, metadata)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     54\u001b[0m     prompt: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     metadata: Optional[List] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m ):\n\u001b[1;32m     62\u001b[0m     input_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_final_prompts(prompt, system_prompt)\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlamini_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/lamini.py:77\u001b[0m, in \u001b[0;36mLamini.generate\u001b[0;34m(self, prompt, model_name, output_type, max_tokens, max_new_tokens, callback, metadata)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     70\u001b[0m     req_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_llm_req_map(\n\u001b[1;32m     71\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     72\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39mmax_new_tokens,\n\u001b[1;32m     76\u001b[0m     )\n\u001b[0;32m---> 77\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/utils/completion.py:15\u001b[0m, in \u001b[0;36mCompletion.generate\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, params):\n\u001b[0;32m---> 15\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mmake_web_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_prefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompletions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/rest_requests.py:154\u001b[0m, in \u001b[0;36mmake_web_request\u001b[0;34m(key, url, http_method, json)\u001b[0m\n\u001b[1;32m    149\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m key,\n\u001b[1;32m    152\u001b[0m     }\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing API Key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     version \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlamini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Missing API Key"
     ]
    }
   ],
   "source": [
    "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb75601-57f0-4cfd-bd10-35976fc5001b",
   "metadata": {},
   "source": [
    "# Lab 2: Where finetuning fits in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe784ad0-436d-434c-b793-40c8b90848fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f87c50e-bfea-4222-a0dd-719e117efbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "036f75ff-3f67-46d1-a0ac-47a61c2d3d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zstandard\n",
      "  Downloading zstandard-0.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Downloading zstandard-0.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard\n",
      "Successfully installed zstandard-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8371c6de-8a1c-4902-bb30-890c06312f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained dataset:\n",
      "{'instruction': 'When did Virgin Australia start operating?', 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}\n",
      "{'instruction': 'Which is a species of fish? Tope or Rope', 'context': '', 'response': 'Tope', 'category': 'classification'}\n",
      "{'instruction': 'Why can camels survive for long without water?', 'context': '', 'response': 'Camels use the fat in their humps to keep them filled with energy and hydration for long periods of time.', 'category': 'open_qa'}\n",
      "{'instruction': \"Alice's parents have three daughters: Amy, Jessy, and what’s the name of the third daughter?\", 'context': '', 'response': 'The name of the third daughter is Alice', 'category': 'open_qa'}\n",
      "{'instruction': 'When was Tomoaki Komorida born?', 'context': 'Komorida was born in Kumamoto Prefecture on July 10, 1981. After graduating from high school, he joined the J1 League club Avispa Fukuoka in 2000. Although he debuted as a midfielder in 2001, he did not play much and the club was relegated to the J2 League at the end of the 2001 season. In 2002, he moved to the J2 club Oita Trinita. He became a regular player as a defensive midfielder and the club won the championship in 2002 and was promoted in 2003. He played many matches until 2005. In September 2005, he moved to the J2 club Montedio Yamagata. In 2006, he moved to the J2 club Vissel Kobe. Although he became a regular player as a defensive midfielder, his gradually was played less during the summer. In 2007, he moved to the Japan Football League club Rosso Kumamoto (later Roasso Kumamoto) based in his local region. He played as a regular player and the club was promoted to J2 in 2008. Although he did not play as much, he still played in many matches. In 2010, he moved to Indonesia and joined Persela Lamongan. In July 2010, he returned to Japan and joined the J2 club Giravanz Kitakyushu. He played often as a defensive midfielder and center back until 2012 when he retired.', 'response': 'Tomoaki Komorida was born on July 10,1981.', 'category': 'closed_qa'}\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "print(\"Pretrained dataset:\")\n",
    "top_n = itertools.islice(pretrained_dataset, n)\n",
    "for i in top_n:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a64572c-5e9f-4d9e-b5b9-62b0440402e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I evaluate the performance and quality...</td>\n",
       "      <td>There are several metrics that can be used to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I find information about the code's approa...</td>\n",
       "      <td>Yes, the code includes methods for submitting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Lamini AI handle requests for generat...</td>\n",
       "      <td>Lamini AI offers features for generating text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does the `submit_job()` function expose any ad...</td>\n",
       "      <td>It is unclear which `submit_job()` function is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does the `add_data()` function support differe...</td>\n",
       "      <td>No, the `add_data()` function does not support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>Does Lamini have the ability to understand and...</td>\n",
       "      <td>Yes, Lamini has the ability to understand and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Can I fine-tune the pre-trained models provide...</td>\n",
       "      <td>Yes, you can fine-tune the pre-trained models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>Can Lamini generate text that is suitable for ...</td>\n",
       "      <td>Yes, Lamini can generate text that is suitable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>Does the documentation have a secret code that...</td>\n",
       "      <td>I wish! This documentation only talks about La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>Can I teach Lamini about things that I like or...</td>\n",
       "      <td>Absolutely! One of the fascinating aspects of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question                                             answer\n",
       "0     How can I evaluate the performance and quality...  There are several metrics that can be used to ...\n",
       "1     Can I find information about the code's approa...  Yes, the code includes methods for submitting ...\n",
       "2     How does Lamini AI handle requests for generat...  Lamini AI offers features for generating text ...\n",
       "3     Does the `submit_job()` function expose any ad...  It is unclear which `submit_job()` function is...\n",
       "4     Does the `add_data()` function support differe...  No, the `add_data()` function does not support...\n",
       "...                                                 ...                                                ...\n",
       "1395  Does Lamini have the ability to understand and...  Yes, Lamini has the ability to understand and ...\n",
       "1396  Can I fine-tune the pre-trained models provide...  Yes, you can fine-tune the pre-trained models ...\n",
       "1397  Can Lamini generate text that is suitable for ...  Yes, Lamini can generate text that is suitable...\n",
       "1398  Does the documentation have a secret code that...  I wish! This documentation only talks about La...\n",
       "1399  Can I teach Lamini about things that I like or...  Absolutely! One of the fascinating aspects of ...\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_dataset_df = pd.read_parquet(\"hf://datasets/kotzeje/lamini_docs.jsonl/data/train-00000-of-00001-6359aa989b671345.parquet\")\n",
    "# instruction_dataset_df.head()\n",
    "instruction_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a88df3f3-4312-4b34-abe9-8ac032a0a6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How can I evaluate the performance and quality of the generated text from Lamini models?There are several metrics that can be used to evaluate the performance and quality of generated text from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how well the model predicts the next word in a sequence, while BLEU score measures the similarity between the generated text and a reference text. Human evaluation involves having human judges rate the quality of the generated text based on factors such as coherence, fluency, and relevance. It is recommended to use a combination of these metrics for a comprehensive evaluation of the model's performance.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = instruction_dataset_df.to_dict()\n",
    "text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d7a6e60-df00-4bca-b892-91c6340ed97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"question\" in examples and \"answer\" in examples:\n",
    "    text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "elif \"instruction\" in examples and \"response\" in examples:\n",
    "    text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
    "elif \"input\" in examples and \"output\" in examples:\n",
    "    text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "else:\n",
    "    text = examples[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78f06bbe-4a72-4d3f-9fdd-724e36070fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_qa = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "{answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3150d4f0-5a90-4ed6-a1b4-1305482a4fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Question:\\nHow can I evaluate the performance and quality of the generated text from Lamini models?\\n\\n### Answer:\\nThere are several metrics that can be used to evaluate the performance and quality of generated text from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how well the model predicts the next word in a sequence, while BLEU score measures the similarity between the generated text and a reference text. Human evaluation involves having human judges rate the quality of the generated text based on factors such as coherence, fluency, and relevance. It is recommended to use a combination of these metrics for a comprehensive evaluation of the model's performance.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = examples[\"question\"][0]\n",
    "answer = examples[\"answer\"][0]\n",
    "\n",
    "text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)\n",
    "text_with_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3eddaeda-37ad-4a77-b171-c48cd8fd2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_q = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef174505-5688-4ca0-ae24-450e11dfdf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(examples[\"question\"])\n",
    "finetuning_dataset_text_only = []\n",
    "finetuning_dataset_question_answer = []\n",
    "for i in range(num_examples):\n",
    "    question = examples[\"question\"][i]\n",
    "    answer = examples[\"answer\"][i]\n",
    "\n",
    "    text_with_prompt_template_qa = prompt_template_qa.format(question=question, answer=answer)\n",
    "    finetuning_dataset_text_only.append({\"text\": text_with_prompt_template})\n",
    "\n",
    "    text_with_prompt_template_q = prompt_template_q.format(question=question, answer=answer)\n",
    "    finetuning_dataset_question_answer.append({\"question\": text_with_prompt_template_q})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3013bad3-9cc1-420b-ad47-7e8d1d8fdb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '### Question:\\n'\n",
      "         'How can I evaluate the performance and quality of the generated text '\n",
      "         'from Lamini models?\\n'\n",
      "         '\\n'\n",
      "         '### Answer:\\n'\n",
      "         'There are several metrics that can be used to evaluate the '\n",
      "         'performance and quality of generated text from Lamini models, '\n",
      "         'including perplexity, BLEU score, and human evaluation. Perplexity '\n",
      "         'measures how well the model predicts the next word in a sequence, '\n",
      "         'while BLEU score measures the similarity between the generated text '\n",
      "         'and a reference text. Human evaluation involves having human judges '\n",
      "         'rate the quality of the generated text based on factors such as '\n",
      "         'coherence, fluency, and relevance. It is recommended to use a '\n",
      "         'combination of these metrics for a comprehensive evaluation of the '\n",
      "         \"model's performance.\"}\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuning_dataset_text_only[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "522e610e-485f-4e0c-94ad-53e2872eb630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '### Question:\\n'\n",
      "             'How can I evaluate the performance and quality of the generated '\n",
      "             'text from Lamini models?\\n'\n",
      "             '\\n'\n",
      "             '### Answer:'}\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuning_dataset_question_answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a4d2427-dc90-420d-8c92-2e84005e5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(f\"lamini_docs_processed.jsonl\", \"w\") as writer:\n",
    "    writer.write_all(finetuning_dataset_question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33c5f56c-8c4f-4fdf-8137-9a411d6b9f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6021f3bc9c42f7ad5bfb1c3a22f8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ba9d32e534aaf81e45753ba41e7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/615k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41981fde70f24074b259868e8f77c34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/83.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd94743541b4f208d1eaa0ff48bf8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42900ffe5bd450ab1bc1d42cff5567a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 140\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset_name = \"lamini/lamini_docs\"\n",
    "finetuning_dataset = load_dataset(finetuning_dataset_name)\n",
    "print(finetuning_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855419c-5718-437e-8040-c348b1215570",
   "metadata": {},
   "source": [
    "# Lab 3: Instruction tuning lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1c7e1de-5dec-4909-b527-a0a8460454bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import jsonlines\n",
    "\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "from llama import BasicModelRunner\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21864ec2-cb5d-4ab3-865f-59de8dbf97fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5daa5b9823aa4bdcb547194c3ea2a6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True) # streaming为True表示流式加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df12ed02-776e-4cfe-8aff-a7a06f1c1ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained dataset:\n",
      "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
      "{'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the three primary colors?\\n\\n### Response:\\nThe three primary colors are red, blue, and yellow.'}\n",
      "{'instruction': 'Describe the structure of an atom.', 'input': '', 'output': 'An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe the structure of an atom.\\n\\n### Response:\\nAn atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.'}\n",
      "{'instruction': 'How can we reduce air pollution?', 'input': '', 'output': 'There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow can we reduce air pollution?\\n\\n### Response:\\nThere are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.'}\n",
      "{'instruction': 'Describe a time when you had to make a difficult decision.', 'input': '', 'output': 'I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe a time when you had to make a difficult decision.\\n\\n### Response:\\nI had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.'}\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "print(\"Pretrained dataset:\")\n",
    "top_m = itertools.islice(instruction_tuned_dataset, m)\n",
    "for i in top_m:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94e57c40-cd84-4e17-a5de-fd6d8c8a8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further controll\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_template_without_input = \"\"\"Below is an instruction that describes a task, Write a response that appropriately completes\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b184c0d-a411-4c80-8abf-7b58338f5b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for j in top_m:\n",
    "    if not j[\"input\"]:\n",
    "        processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n",
    "    else:\n",
    "        processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"])\n",
    "        \n",
    "    processed_data.append({\"input\":processed_prompt, \"output\":j[\"output\"]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5011ae25-541d-4dee-bd34-23c5c85fa097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85aa4be8-39a8-4515-a6a7-9cb1a583cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ae21d19-730c-4f6a-9d29-a6a2d1de3796",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Missing API Key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/rest_requests.py:151\u001b[0m, in \u001b[0;36mmake_web_request\u001b[0;34m(key, url, http_method, json)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBearer \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m,\n\u001b[1;32m    152\u001b[0m     }\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m non_instruct_output \u001b[38;5;241m=\u001b[39m \u001b[43mnon_instruct_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me how to train my dog to sit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/runners/base_runner.py:42\u001b[0m, in \u001b[0;36mBaseRunner.__call__\u001b[0;34m(self, prompt, system_prompt, output_type, max_tokens, max_new_tokens, callback, metadata)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     34\u001b[0m     prompt: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     metadata: Optional[List] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m ):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/runners/base_runner.py:64\u001b[0m, in \u001b[0;36mBaseRunner.call\u001b[0;34m(self, prompt, system_prompt, output_type, max_tokens, max_new_tokens, callback, metadata)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     54\u001b[0m     prompt: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     metadata: Optional[List] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m ):\n\u001b[1;32m     62\u001b[0m     input_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_final_prompts(prompt, system_prompt)\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlamini_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/lamini.py:77\u001b[0m, in \u001b[0;36mLamini.generate\u001b[0;34m(self, prompt, model_name, output_type, max_tokens, max_new_tokens, callback, metadata)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     70\u001b[0m     req_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_llm_req_map(\n\u001b[1;32m     71\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     72\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39mmax_new_tokens,\n\u001b[1;32m     76\u001b[0m     )\n\u001b[0;32m---> 77\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/utils/completion.py:15\u001b[0m, in \u001b[0;36mCompletion.generate\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, params):\n\u001b[0;32m---> 15\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mmake_web_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_prefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompletions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.8/site-packages/lamini/api/rest_requests.py:154\u001b[0m, in \u001b[0;36mmake_web_request\u001b[0;34m(key, url, http_method, json)\u001b[0m\n\u001b[1;32m    149\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m key,\n\u001b[1;32m    152\u001b[0m     }\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing API Key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     version \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlamini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Missing API Key"
     ]
    }
   ],
   "source": [
    "non_instruct_output = non_instruct_model(\"Tell me how to train my dog to sit\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40ba22cd-fa54-4456-b28a-128ff02ac5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96971ca9705e42d687cb7a9a58800645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e444bca255974c70898de6952bde7fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e76ca8f11fd45dc89ae9f610d511010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c7d33764c04bd7a0aaa92043c106e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683f6348ca3d476baf88349009194bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "055e1235-9e84-4626-a4f6-1d532b24e54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (1831395828.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[68], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def interence(text, model, tokenizer, max_input_tokens=1000, max_output_token):\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def interence(text, model, tokenizer, max_input_tokens=1000, max_output_token):\n",
    "    # Tokenize\n",
    "    input_ids = tokenizer.encode(\n",
    "        text,\n",
    "        return_tensor=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_tokens\n",
    "    )\n",
    "\n",
    "    # Generate\n",
    "    device = model.device\n",
    "    generated_tokens_with_prompt = model.generate(\n",
    "        input_ids=input_ids.to(device),\n",
    "        max_length=max_output_tokens\n",
    "    )\n",
    "\n",
    "    # Decode\n",
    "    generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt)\n",
    "\n",
    "    # Strip the prompt\n",
    "    generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "    return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e17bfd-4668-4ac4-9ac3-58ee1b8a92d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
